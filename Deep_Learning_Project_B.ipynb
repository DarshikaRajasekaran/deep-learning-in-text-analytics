{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk.data\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import gensim\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, Dropout, Flatten\n",
    "from keras.layers import Activation\n",
    "import numpy as np\n",
    "import chardet\n",
    "import logging\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,Dropout,Flatten\n",
    "from keras.layers import Conv1D,MaxPooling1D,AveragePooling1D\n",
    "from keras.layers import LSTM,Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, roc_auc_score, precision_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(dataframe,stop):\n",
    "#Cleaning text    \n",
    "    dataframe[\"doc\"] = dataframe['text']\n",
    "#Remove numbers\n",
    "    dataframe.loc[:,\"doc\"] = dataframe.doc.str.replace(r'\\d+','')\n",
    "#Remove floats\n",
    "    dataframe.loc[:,\"doc\"] = dataframe.doc.astype(str).replace(r'(\\d*\\.?\\d*)','')\n",
    "#Remove Punctuation\n",
    "    dataframe.loc[:,\"doc\"] = dataframe.doc.astype(str).apply(lambda x : \" \".join(re.findall('[\\w]+',x)))\n",
    "#Convert to lower text\n",
    "    dataframe.loc[:,\"doc\"] = dataframe.doc.astype(str).apply(lambda x: \" \".join(x.lower() for x in x.split()))      \n",
    "#Stop words removal\n",
    "    if stop == True:\n",
    "        dataframe.loc[:,\"doc\"] = dataframe.loc[:,\"doc\"].astype(str)\n",
    "        stop = stopwords.words('english')\n",
    "        dataframe.loc[:,\"doc\"] = dataframe.loc[:,\"doc\"].apply(lambda x: \" \".join(x.lower() for x in str(x).split() if x not in stop))\n",
    "#Reomve top 50 common words\n",
    "    freq = pd.Series(' '.join(dataframe['doc']).split()).value_counts()[:50]\n",
    "    freq = list(freq.index)\n",
    "    dataframe.loc[:,'doc'] = dataframe.loc[:,'doc'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "#Stemming        \n",
    "    st = PorterStemmer()\n",
    "    dataframe.loc[:,'doc'] = dataframe.loc[:,'doc'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "\n",
    "# Moving cleaned text to another column\n",
    "    dataframe['cleaned_text'] = dataframe[\"doc\"]\n",
    "#Tokenization                               \n",
    "    dataframe.loc[:,\"doc\"] = dataframe.loc[:,\"doc\"].apply(nltk.word_tokenize)\n",
    "    \n",
    "    return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text1(dataframe):\n",
    "#Cleaning text    \n",
    "    dataframe[\"doc\"] = dataframe['text']\n",
    "#Remove numbers\n",
    "    dataframe.loc[:,\"doc\"] = dataframe.doc.str.replace(r'\\d+','')\n",
    "#Remove floats\n",
    "    dataframe.loc[:,\"doc\"] = dataframe.doc.astype(str).replace(r'(\\d*\\.?\\d*)','')\n",
    "#Remove Punctuation\n",
    "    dataframe.loc[:,\"doc\"] = dataframe.doc.astype(str).apply(lambda x : \" \".join(re.findall('[\\w]+',x)))\n",
    "#Convert to lower text\n",
    "    dataframe.loc[:,\"doc\"] = dataframe.doc.astype(str).apply(lambda x: \" \".join(x.lower() for x in x.split()))      \n",
    "#Stop words removal\n",
    "    stop = stopwords.words('english')\n",
    "    dataframe.loc[:,'doc'] = dataframe.loc[:,'doc'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "#Reomve top 50 common words\n",
    "    freq = pd.Series(' '.join(dataframe['doc']).split()).value_counts()[:50]\n",
    "    freq = list(freq.index)\n",
    "    dataframe.loc[:,'doc'] = dataframe.loc[:,'doc'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "#Stemming        \n",
    "    st = PorterStemmer()\n",
    "    dataframe.loc[:,'doc'] = dataframe.loc[:,'doc'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "\n",
    "# Moving cleaned text to another column\n",
    "    dataframe['cleaned_text'] = dataframe[\"doc\"]\n",
    "#Tokenization                               \n",
    "    dataframe.loc[:,\"doc\"] = dataframe.loc[:,\"doc\"].apply(nltk.word_tokenize)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2c_model(doc,size,window,min_count,workers,iter,sg,length,numepoch):    \n",
    "    model = gensim.models.Word2Vec(size=size, window=window, min_count=min_count, workers=workers,iter=iter,sg=sg)\n",
    "    model.build_vocab(doc)\n",
    "    model.train(doc,total_examples=length,epochs = numepoch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert clean text into sequence base on word2vec\n",
    "def text2seq(doc, w2v, seq_len, emb_size):\n",
    "    padding = np.array([0 for __ in range(emb_size)])\n",
    "    seq = []\n",
    "    for token in doc[: seq_len]:\n",
    "        try:\n",
    "            seq.append(w2v.wv[token])\n",
    "        except:\n",
    "            aa = 1\n",
    "\n",
    "    seq += [padding for __ in range(seq_len - len(seq))]\n",
    "    #print(len(seq))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(series):\n",
    "    values=sorted(list(set(series)))\n",
    "    return np.vstack(map(lambda x: [x==v for v in values],series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(dataframe, w2v,seq_len, emb_size, target_col):\n",
    "    X = dataframe['doc'].apply(lambda doc: text2seq(doc, w2v, seq_len, emb_size))\n",
    "    X = np.vstack(X).reshape(len(dataframe), seq_len, emb_size)\n",
    "    y = one_hot(dataframe[target_col])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Model building \n",
    "# def model1(seq_len, emb_size, num_labels):\n",
    "#     input_layer = Input(shape=(seq_len, emb_size))\n",
    "#     x = Conv1D(32, 3, activation='relu')(input_layer)\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = Dense(64, activation='relu')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     output_layer = Dense(num_labels, activation='softmax')(x)\n",
    "#     model = Model(input_layer, output_layer)\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2():\n",
    "    input_layer = Input(shape=(100, 100))\n",
    "    x = Conv1D(32, 3, activation='relu')(input_layer)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output_layer = Dense(9, activation='softmax')(x)\n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def define_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(882, 100))\n",
    "#     model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(10, activation='relu'))\n",
    "#     model.add(Dense(2, activation='sigmoid'))\n",
    "#     # compile network\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     # summarize defined model\n",
    "#     #model.summary()\n",
    "#     #plot_model(model, to_file='model.png', show_shapes=True)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_layer = Input(shape=(100, 100))\n",
    "    x = Conv1D(32, 3, activation='relu')(input_layer)\n",
    "    x = MaxPooling1D(pool_size=2)(x)  \n",
    "    x = LSTM(100, dropout=0.2, recurrent_dropout=0.2)(x) \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output_layer = Dense(9, activation='softmax')(x)\n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change any numbers except those two I highlighted, or add any dense layers or change activations, \n",
    "# dropout rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2():\n",
    "    input_layer = Input(shape=(100,100)) #These two numbers cannot change\n",
    "    x = Conv1D(32, 3, activation='relu')(input_layer)\n",
    "    x = MaxPooling1D(pool_size=2)(x)  \n",
    "    x = LSTM(100, return_sequences = True,dropout=0.2,recurrent_dropout=0.05)(input_layer)\n",
    "    x = Flatten()(x)\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    output_layer = Dense(9, activation='softmax')(x) # 9 is the number represent how many Labels we have 0-8\n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X,y,weightsfile,num_labels,seq_len,emb_size,epochs):\n",
    "    checkpoint = ModelCheckpoint(weightsfile, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    model_dl = model1(seq_len, emb_size, num_labels)\n",
    "    model_dl.fit(X, y, epochs=epochs, batch_size=16,callbacks=callbacks_list, validation_split=0.2)\n",
    "    return model_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20030006121</td>\n",
       "      <td>Passive radio frequency identification system ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20030009666</td>\n",
       "      <td>Methods and apparatus for efficient computatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20030014337</td>\n",
       "      <td>Systems, methods and computer program products...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20030019942</td>\n",
       "      <td>System and method for electronically readable ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20030033242</td>\n",
       "      <td>System and method for automated process of dea...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           ID                                               text  \\\n",
       "0           0  20030006121  Passive radio frequency identification system ...   \n",
       "1           1  20030009666  Methods and apparatus for efficient computatio...   \n",
       "2           2  20030014337  Systems, methods and computer program products...   \n",
       "3           3  20030019942  System and method for electronically readable ...   \n",
       "4           4  20030033242  System and method for automated process of dea...   \n",
       "\n",
       "   Label  \n",
       "0      8  \n",
       "1      0  \n",
       "2      8  \n",
       "3      8  \n",
       "4      6  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text column\n",
    "df = clean_text1(df)\n",
    "#Assign processed column to be the target column for the word2vec\n",
    "doc = df.doc\n",
    "#create a word2vec model to use as embedding layers in CNN\n",
    "w2c = w2c_model(doc,size=100,window=5,min_count=1,workers=6,iter=10,sg=0,length=len(doc),numepoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "      <th>doc</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20030006121</td>\n",
       "      <td>Passive radio frequency identification system ...</td>\n",
       "      <td>8</td>\n",
       "      <td>[passiv, radio, frequenc, identif, identifi, t...</td>\n",
       "      <td>passiv radio frequenc identif identifi track c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20030009666</td>\n",
       "      <td>Methods and apparatus for efficient computatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, apparatu, effici, comput, way, chain,...</td>\n",
       "      <td>method apparatu effici comput way chain crypto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20030014337</td>\n",
       "      <td>Systems, methods and computer program products...</td>\n",
       "      <td>8</td>\n",
       "      <td>[system, method, program, product, perform, ge...</td>\n",
       "      <td>system method program product perform gener co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20030019942</td>\n",
       "      <td>System and method for electronically readable ...</td>\n",
       "      <td>8</td>\n",
       "      <td>[electron, readabl, power, sourc, improv, cont...</td>\n",
       "      <td>electron readabl power sourc improv contain el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20030033242</td>\n",
       "      <td>System and method for automated process of dea...</td>\n",
       "      <td>6</td>\n",
       "      <td>[autom, process, deal, structur, autom, deal, ...</td>\n",
       "      <td>autom process deal structur autom deal custom ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           ID                                               text  \\\n",
       "0           0  20030006121  Passive radio frequency identification system ...   \n",
       "1           1  20030009666  Methods and apparatus for efficient computatio...   \n",
       "2           2  20030014337  Systems, methods and computer program products...   \n",
       "3           3  20030019942  System and method for electronically readable ...   \n",
       "4           4  20030033242  System and method for automated process of dea...   \n",
       "\n",
       "   Label                                                doc  \\\n",
       "0      8  [passiv, radio, frequenc, identif, identifi, t...   \n",
       "1      0  [method, apparatu, effici, comput, way, chain,...   \n",
       "2      8  [system, method, program, product, perform, ge...   \n",
       "3      8  [electron, readabl, power, sourc, improv, cont...   \n",
       "4      6  [autom, process, deal, structur, autom, deal, ...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  passiv radio frequenc identif identifi track c...  \n",
       "1  method apparatu effici comput way chain crypto...  \n",
       "2  system method program product perform gener co...  \n",
       "3  electron readabl power sourc improv contain el...  \n",
       "4  autom process deal structur autom deal custom ...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sequence and embedding layer base on word2vec \n",
    "X, y = prepro(df,w2c,seq_len=100, emb_size=100,target_col='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "CNN = KerasClassifier(build_fn=build_model2, \n",
    "                      batch_size=100,\n",
    "                            epochs=10)\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(882, 100, 100)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "793/793 [==============================] - 17s 21ms/step - loss: 1.5652 - acc: 0.4338\n",
      "Epoch 2/10\n",
      "793/793 [==============================] - 3s 3ms/step - loss: 0.7713 - acc: 0.7251\n",
      "Epoch 3/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.3681 - acc: 0.8663\n",
      "Epoch 4/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.1855 - acc: 0.9571\n",
      "Epoch 5/10\n",
      "793/793 [==============================] - 3s 3ms/step - loss: 0.1069 - acc: 0.9786\n",
      "Epoch 6/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.0472 - acc: 0.9924\n",
      "Epoch 7/10\n",
      "793/793 [==============================] - 3s 3ms/step - loss: 0.0519 - acc: 0.9899\n",
      "Epoch 8/10\n",
      "793/793 [==============================] - 3s 3ms/step - loss: 0.0538 - acc: 0.9912\n",
      "Epoch 9/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.0450 - acc: 0.9861\n",
      "Epoch 10/10\n",
      "793/793 [==============================] - 3s 3ms/step - loss: 0.0423 - acc: 0.9861\n",
      "Epoch 1/10\n",
      "793/793 [==============================] - 17s 21ms/step - loss: 1.5888 - acc: 0.4439\n",
      "Epoch 2/10\n",
      "793/793 [==============================] - 3s 3ms/step - loss: 0.7347 - acc: 0.7339\n",
      "Epoch 3/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.3773 - acc: 0.8815\n",
      "Epoch 4/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.1726 - acc: 0.9533\n",
      "Epoch 5/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.0868 - acc: 0.9849\n",
      "Epoch 6/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.0532 - acc: 0.9887\n",
      "Epoch 7/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.0691 - acc: 0.9811\n",
      "Epoch 8/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.0482 - acc: 0.9849\n",
      "Epoch 9/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.0388 - acc: 0.9937\n",
      "Epoch 10/10\n",
      "793/793 [==============================] - 3s 4ms/step - loss: 0.0275 - acc: 0.9899\n",
      "Epoch 1/10\n",
      "794/794 [==============================] - 18s 23ms/step - loss: 1.5862 - acc: 0.4547\n",
      "Epoch 2/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.7199 - acc: 0.7456\n",
      "Epoch 3/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.3560 - acc: 0.8665\n",
      "Epoch 4/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.1599 - acc: 0.9635\n",
      "Epoch 5/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0824 - acc: 0.9824\n",
      "Epoch 6/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0641 - acc: 0.9849\n",
      "Epoch 7/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0509 - acc: 0.9899\n",
      "Epoch 8/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0374 - acc: 0.9924\n",
      "Epoch 9/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0428 - acc: 0.9937\n",
      "Epoch 10/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0330 - acc: 0.9924\n",
      "Epoch 1/10\n",
      "794/794 [==============================] - 19s 24ms/step - loss: 1.5811 - acc: 0.4723\n",
      "Epoch 2/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.7635 - acc: 0.7330\n",
      "Epoch 3/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.3469 - acc: 0.8866\n",
      "Epoch 4/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.1671 - acc: 0.9484\n",
      "Epoch 5/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0978 - acc: 0.9798\n",
      "Epoch 6/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0769 - acc: 0.9824\n",
      "Epoch 7/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0484 - acc: 0.9836\n",
      "Epoch 8/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0434 - acc: 0.9887\n",
      "Epoch 9/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0313 - acc: 0.9899\n",
      "Epoch 10/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0357 - acc: 0.9937\n",
      "Epoch 1/10\n",
      "794/794 [==============================] - 18s 22ms/step - loss: 1.5564 - acc: 0.4534\n",
      "Epoch 2/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.6619 - acc: 0.7846\n",
      "Epoch 3/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.3498 - acc: 0.8778\n",
      "Epoch 4/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.1502 - acc: 0.9610\n",
      "Epoch 5/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0833 - acc: 0.9798\n",
      "Epoch 6/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0727 - acc: 0.9849\n",
      "Epoch 7/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0591 - acc: 0.9912\n",
      "Epoch 8/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0467 - acc: 0.9887\n",
      "Epoch 9/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0293 - acc: 0.9950\n",
      "Epoch 10/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0252 - acc: 0.9924\n",
      "Epoch 1/10\n",
      "794/794 [==============================] - 18s 22ms/step - loss: 1.5860 - acc: 0.4207\n",
      "Epoch 2/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.7797 - acc: 0.7128\n",
      "Epoch 3/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.3661 - acc: 0.8778\n",
      "Epoch 4/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.1823 - acc: 0.9446\n",
      "Epoch 5/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0972 - acc: 0.9773\n",
      "Epoch 6/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0657 - acc: 0.9824\n",
      "Epoch 7/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0525 - acc: 0.9887\n",
      "Epoch 8/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0463 - acc: 0.9899\n",
      "Epoch 9/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0294 - acc: 0.9950\n",
      "Epoch 10/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0232 - acc: 0.9950\n",
      "Epoch 1/10\n",
      "794/794 [==============================] - 18s 22ms/step - loss: 1.5198 - acc: 0.5101\n",
      "Epoch 2/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.7034 - acc: 0.7645\n",
      "Epoch 3/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.3340 - acc: 0.8980\n",
      "Epoch 4/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.1623 - acc: 0.9559\n",
      "Epoch 5/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0615 - acc: 0.9874\n",
      "Epoch 6/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0428 - acc: 0.9887\n",
      "Epoch 7/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0305 - acc: 0.9924\n",
      "Epoch 8/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0273 - acc: 0.9912\n",
      "Epoch 9/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0172 - acc: 0.9975\n",
      "Epoch 10/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0151 - acc: 0.9975\n",
      "Epoch 1/10\n",
      "794/794 [==============================] - 19s 24ms/step - loss: 1.4292 - acc: 0.5139\n",
      "Epoch 2/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.6690 - acc: 0.7620\n",
      "Epoch 3/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.3336 - acc: 0.9018\n",
      "Epoch 4/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.1178 - acc: 0.9761\n",
      "Epoch 5/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0620 - acc: 0.9887\n",
      "Epoch 6/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0504 - acc: 0.9912\n",
      "Epoch 7/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0386 - acc: 0.9924\n",
      "Epoch 8/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0422 - acc: 0.9924\n",
      "Epoch 9/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0241 - acc: 0.9962\n",
      "Epoch 10/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0264 - acc: 0.9924\n",
      "Epoch 1/10\n",
      "794/794 [==============================] - 20s 25ms/step - loss: 1.5691 - acc: 0.4521\n",
      "Epoch 2/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.7331 - acc: 0.7544\n",
      "Epoch 3/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.3495 - acc: 0.8980\n",
      "Epoch 4/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.1528 - acc: 0.9660\n",
      "Epoch 5/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.1046 - acc: 0.9824\n",
      "Epoch 6/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0654 - acc: 0.9849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0548 - acc: 0.9874\n",
      "Epoch 8/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0493 - acc: 0.9887\n",
      "Epoch 9/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0423 - acc: 0.9924\n",
      "Epoch 10/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.0267 - acc: 0.9950\n",
      "Epoch 1/10\n",
      "794/794 [==============================] - 20s 25ms/step - loss: 1.5355 - acc: 0.4962\n",
      "Epoch 2/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.7501 - acc: 0.7431\n",
      "Epoch 3/10\n",
      "794/794 [==============================] - 3s 4ms/step - loss: 0.3342 - acc: 0.8879\n",
      "Epoch 4/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.1488 - acc: 0.9610\n",
      "Epoch 5/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0809 - acc: 0.9824\n",
      "Epoch 6/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0825 - acc: 0.9761\n",
      "Epoch 7/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0401 - acc: 0.9912\n",
      "Epoch 8/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0422 - acc: 0.9950\n",
      "Epoch 9/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0298 - acc: 0.9950\n",
      "Epoch 10/10\n",
      "794/794 [==============================] - 3s 3ms/step - loss: 0.0273 - acc: 0.9924\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.77      0.69       274\n",
      "          1       0.53      0.49      0.51        84\n",
      "          2       0.18      0.14      0.16        77\n",
      "          3       0.81      0.57      0.67        61\n",
      "          4       0.67      0.11      0.19        37\n",
      "          5       0.52      0.38      0.44        42\n",
      "          6       0.55      0.27      0.36        45\n",
      "          7       1.00      0.47      0.64        34\n",
      "          8       0.48      0.61      0.54       228\n",
      "\n",
      "avg / total       0.56      0.55      0.54       882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use cross validation predict to make prediction on the entire dataset\n",
    "cnn_pred = cross_val_predict(CNN, X, df.Label, cv=10)\n",
    "\n",
    "#Use classification report to get the precision & recall table, compare with prediction and actual labels\n",
    "print(classification_report(df.Label,cnn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.21541950113379"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score\n",
    "accuracy_score(df.Label, cnn_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN1 = KerasClassifier(build_fn=define_model, \n",
    "#                             epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(CNN, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring = {'acc': 'accuracy',\n",
    "#            'precision': 'precision_macro',\n",
    "#            'recall': 'recall_macro',\n",
    "#            'f1_score' : 'f1_macro'}\n",
    "# cnn_scores = cross_validate(CNN, X, df.Label, scoring=scoring,\n",
    "#                          cv=10, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cnn_scores.keys())\n",
    "# print(cnn_scores['test_acc'].mean())\n",
    "# print(cnn_scores['test_precision'].mean())\n",
    "# print(cnn_scores['test_recall'].mean())\n",
    "# print(cnn_scores['test_f1_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Use cross validation predict to make prediction on the entire dataset\n",
    "# cnn_pred = cross_val_predict(CNN, X, df.Label, cv=10)\n",
    "\n",
    "# #Use classification report to get the precision & recall table, compare with prediction and actual labels\n",
    "# print(classification_report(df.Label,cnn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(df.Label, cnn_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>doc</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   ID  text  doc  cleaned_text\n",
       "Label                                          \n",
       "0             274  274   274  274           274\n",
       "1              84   84    84   84            84\n",
       "2              77   77    77   77            77\n",
       "3              61   61    61   61            61\n",
       "4              37   37    37   37            37\n",
       "5              42   42    42   42            42\n",
       "6              45   45    45   45            45\n",
       "7              34   34    34   34            34\n",
       "8             228  228   228  228           228"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new dataframe that only contains label 0 & 8, both contains 74 labels each\n",
    "d1 = df[df['Label']==0].sample(74)\n",
    "d2 = df[df['Label']==8].sample(74)\n",
    "#Append them into a new dataframe\n",
    "d3 = d1.append(d2, ignore_index=True)\n",
    "\n",
    "#Create new dataframe that only contains label 1 to 7\n",
    "d4 = df[(df['Label'] != 0 ) & (df['Label'] != 8)]\n",
    "#Append them together\n",
    "ds = d4.append(d3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y = prepro(ds,w2c,seq_len=100, emb_size=100,target_col='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "475/475 [==============================] - 7s 14ms/step - loss: 1.6561 - acc: 0.4021\n",
      "Epoch 2/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.6959 - acc: 0.7874\n",
      "Epoch 3/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.3426 - acc: 0.9179\n",
      "Epoch 4/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.1911 - acc: 0.9642\n",
      "Epoch 5/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.1152 - acc: 0.9832\n",
      "Epoch 6/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0855 - acc: 0.9853\n",
      "Epoch 7/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0664 - acc: 0.9937\n",
      "Epoch 8/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0544 - acc: 0.9853\n",
      "Epoch 9/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0653 - acc: 0.9853\n",
      "Epoch 10/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0583 - acc: 0.9874\n",
      "Epoch 11/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0625 - acc: 0.9895\n",
      "Epoch 12/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0717 - acc: 0.9895\n",
      "Epoch 13/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0654 - acc: 0.9916\n",
      "Epoch 14/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0343 - acc: 0.9916\n",
      "Epoch 15/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0557 - acc: 0.9916\n",
      "Epoch 16/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0554 - acc: 0.9916\n",
      "Epoch 17/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0427 - acc: 0.9916\n",
      "Epoch 18/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0517 - acc: 0.9895\n",
      "Epoch 19/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0227 - acc: 0.9916\n",
      "Epoch 20/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0558 - acc: 0.9916\n",
      "Epoch 1/20\n",
      "475/475 [==============================] - 7s 15ms/step - loss: 1.7411 - acc: 0.3621\n",
      "Epoch 2/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.7250 - acc: 0.7895\n",
      "Epoch 3/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.3726 - acc: 0.9011\n",
      "Epoch 4/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.2081 - acc: 0.9579\n",
      "Epoch 5/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.1363 - acc: 0.9853\n",
      "Epoch 6/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0996 - acc: 0.9874\n",
      "Epoch 7/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0712 - acc: 0.9895\n",
      "Epoch 8/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0896 - acc: 0.9853\n",
      "Epoch 9/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0535 - acc: 0.9916\n",
      "Epoch 10/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0619 - acc: 0.9874\n",
      "Epoch 11/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0496 - acc: 0.9916\n",
      "Epoch 12/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0593 - acc: 0.9895\n",
      "Epoch 13/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0788 - acc: 0.9874\n",
      "Epoch 14/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0549 - acc: 0.9895\n",
      "Epoch 15/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0582 - acc: 0.9874\n",
      "Epoch 16/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0430 - acc: 0.9874\n",
      "Epoch 17/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0466 - acc: 0.9895\n",
      "Epoch 18/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0321 - acc: 0.9916\n",
      "Epoch 19/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0538 - acc: 0.9916\n",
      "Epoch 20/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0297 - acc: 0.9937\n",
      "Epoch 1/20\n",
      "475/475 [==============================] - 7s 15ms/step - loss: 1.6315 - acc: 0.4063\n",
      "Epoch 2/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.6582 - acc: 0.8000\n",
      "Epoch 3/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.3527 - acc: 0.9116\n",
      "Epoch 4/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.1909 - acc: 0.9663\n",
      "Epoch 5/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.1085 - acc: 0.9789\n",
      "Epoch 6/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0830 - acc: 0.9895\n",
      "Epoch 7/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0665 - acc: 0.9916\n",
      "Epoch 8/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0533 - acc: 0.9916\n",
      "Epoch 9/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0447 - acc: 0.9916\n",
      "Epoch 10/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0356 - acc: 0.9958\n",
      "Epoch 11/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0375 - acc: 0.9937\n",
      "Epoch 12/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0478 - acc: 0.9937\n",
      "Epoch 13/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0644 - acc: 0.9937\n",
      "Epoch 14/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0409 - acc: 0.9895\n",
      "Epoch 15/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0499 - acc: 0.9895\n",
      "Epoch 16/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0284 - acc: 0.9916\n",
      "Epoch 17/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0384 - acc: 0.9937\n",
      "Epoch 18/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0331 - acc: 0.9916\n",
      "Epoch 19/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0331 - acc: 0.9937\n",
      "Epoch 20/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0282 - acc: 0.9937\n",
      "Epoch 1/20\n",
      "475/475 [==============================] - 7s 16ms/step - loss: 1.6158 - acc: 0.4126\n",
      "Epoch 2/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.6976 - acc: 0.7832\n",
      "Epoch 3/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.3480 - acc: 0.9074\n",
      "Epoch 4/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.1802 - acc: 0.9726\n",
      "Epoch 5/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.1079 - acc: 0.9874\n",
      "Epoch 6/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0697 - acc: 0.9916\n",
      "Epoch 7/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0597 - acc: 0.9958\n",
      "Epoch 8/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0481 - acc: 0.9916\n",
      "Epoch 9/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0428 - acc: 0.9916\n",
      "Epoch 10/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0313 - acc: 0.9958\n",
      "Epoch 11/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0367 - acc: 0.9958\n",
      "Epoch 12/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0335 - acc: 0.9958\n",
      "Epoch 13/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0285 - acc: 0.9958\n",
      "Epoch 14/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0373 - acc: 0.9937\n",
      "Epoch 15/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0348 - acc: 0.9937\n",
      "Epoch 16/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0351 - acc: 0.9937\n",
      "Epoch 17/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0145 - acc: 0.9979\n",
      "Epoch 18/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0289 - acc: 0.9958\n",
      "Epoch 19/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0326 - acc: 0.9937\n",
      "Epoch 20/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0304 - acc: 0.9958\n",
      "Epoch 1/20\n",
      "475/475 [==============================] - 8s 16ms/step - loss: 1.7049 - acc: 0.3705\n",
      "Epoch 2/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.7150 - acc: 0.7811\n",
      "Epoch 3/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.3600 - acc: 0.9158\n",
      "Epoch 4/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.2119 - acc: 0.9558\n",
      "Epoch 5/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.1281 - acc: 0.9874\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0865 - acc: 0.9853\n",
      "Epoch 7/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0780 - acc: 0.9853\n",
      "Epoch 8/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0809 - acc: 0.9874\n",
      "Epoch 9/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0567 - acc: 0.9874\n",
      "Epoch 10/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0525 - acc: 0.9874\n",
      "Epoch 11/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0476 - acc: 0.9895\n",
      "Epoch 12/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0593 - acc: 0.9895\n",
      "Epoch 13/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0510 - acc: 0.9895\n",
      "Epoch 14/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0581 - acc: 0.9853\n",
      "Epoch 15/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0401 - acc: 0.9874\n",
      "Epoch 16/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0456 - acc: 0.9895\n",
      "Epoch 17/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0589 - acc: 0.9874\n",
      "Epoch 18/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0269 - acc: 0.9916\n",
      "Epoch 19/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0408 - acc: 0.9874\n",
      "Epoch 20/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0338 - acc: 0.9916\n",
      "Epoch 1/20\n",
      "475/475 [==============================] - 8s 16ms/step - loss: 1.7050 - acc: 0.3747\n",
      "Epoch 2/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.7264 - acc: 0.7705\n",
      "Epoch 3/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.3654 - acc: 0.9137\n",
      "Epoch 4/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.1840 - acc: 0.9684\n",
      "Epoch 5/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.1165 - acc: 0.9832\n",
      "Epoch 6/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0953 - acc: 0.9853\n",
      "Epoch 7/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0608 - acc: 0.9895\n",
      "Epoch 8/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0549 - acc: 0.9916\n",
      "Epoch 9/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0660 - acc: 0.9874\n",
      "Epoch 10/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0541 - acc: 0.9916\n",
      "Epoch 11/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0544 - acc: 0.9874\n",
      "Epoch 12/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0356 - acc: 0.9916\n",
      "Epoch 13/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0362 - acc: 0.9937\n",
      "Epoch 14/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0399 - acc: 0.9895\n",
      "Epoch 15/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0256 - acc: 0.9958\n",
      "Epoch 16/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0467 - acc: 0.9895\n",
      "Epoch 17/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0515 - acc: 0.9895\n",
      "Epoch 18/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0205 - acc: 0.9958\n",
      "Epoch 19/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0241 - acc: 0.9958\n",
      "Epoch 20/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0452 - acc: 0.9853\n",
      "Epoch 1/20\n",
      "475/475 [==============================] - 8s 16ms/step - loss: 1.7020 - acc: 0.3768\n",
      "Epoch 2/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.6837 - acc: 0.8021\n",
      "Epoch 3/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.3269 - acc: 0.9221\n",
      "Epoch 4/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.1920 - acc: 0.9726\n",
      "Epoch 5/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.1131 - acc: 0.9874\n",
      "Epoch 6/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0753 - acc: 0.9874\n",
      "Epoch 7/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0564 - acc: 0.9937\n",
      "Epoch 8/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0456 - acc: 0.9958\n",
      "Epoch 9/20\n",
      "475/475 [==============================] - 2s 4ms/step - loss: 0.0494 - acc: 0.9916\n",
      "Epoch 10/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0381 - acc: 0.9958\n",
      "Epoch 11/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0346 - acc: 0.9916\n",
      "Epoch 12/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0288 - acc: 0.9958\n",
      "Epoch 13/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0376 - acc: 0.9937\n",
      "Epoch 14/20\n",
      "475/475 [==============================] - 2s 4ms/step - loss: 0.0333 - acc: 0.9937\n",
      "Epoch 15/20\n",
      "475/475 [==============================] - 2s 4ms/step - loss: 0.0342 - acc: 0.9916\n",
      "Epoch 16/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0215 - acc: 0.9979\n",
      "Epoch 17/20\n",
      "475/475 [==============================] - 2s 4ms/step - loss: 0.0262 - acc: 0.9937\n",
      "Epoch 18/20\n",
      "475/475 [==============================] - 2s 4ms/step - loss: 0.0275 - acc: 0.9916\n",
      "Epoch 19/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0206 - acc: 0.9958\n",
      "Epoch 20/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0463 - acc: 0.9916\n",
      "Epoch 1/20\n",
      "475/475 [==============================] - 8s 17ms/step - loss: 1.6751 - acc: 0.3874\n",
      "Epoch 2/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.7177 - acc: 0.8105\n",
      "Epoch 3/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.3852 - acc: 0.9074\n",
      "Epoch 4/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.1791 - acc: 0.9705\n",
      "Epoch 5/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.1197 - acc: 0.9789\n",
      "Epoch 6/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0890 - acc: 0.9895\n",
      "Epoch 7/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0622 - acc: 0.9916\n",
      "Epoch 8/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0545 - acc: 0.9937\n",
      "Epoch 9/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0437 - acc: 0.9937\n",
      "Epoch 10/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0440 - acc: 0.9916\n",
      "Epoch 11/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0421 - acc: 0.9937\n",
      "Epoch 12/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0440 - acc: 0.9937\n",
      "Epoch 13/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0432 - acc: 0.9895\n",
      "Epoch 14/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0373 - acc: 0.9895\n",
      "Epoch 15/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0379 - acc: 0.9937\n",
      "Epoch 16/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0531 - acc: 0.9895\n",
      "Epoch 17/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0240 - acc: 0.9958\n",
      "Epoch 18/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0377 - acc: 0.9874\n",
      "Epoch 19/20\n",
      "475/475 [==============================] - 1s 3ms/step - loss: 0.0326 - acc: 0.9895\n",
      "Epoch 20/20\n",
      "475/475 [==============================] - 2s 3ms/step - loss: 0.0430 - acc: 0.9895\n",
      "Epoch 1/20\n",
      "476/476 [==============================] - 9s 20ms/step - loss: 1.6861 - acc: 0.3950\n",
      "Epoch 2/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.6916 - acc: 0.7899\n",
      "Epoch 3/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.3635 - acc: 0.9034\n",
      "Epoch 4/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.2139 - acc: 0.9601\n",
      "Epoch 5/20\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 0.1397 - acc: 0.9706\n",
      "Epoch 6/20\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 0.1106 - acc: 0.9790\n",
      "Epoch 7/20\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 0.0788 - acc: 0.9895\n",
      "Epoch 8/20\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 0.0645 - acc: 0.9895\n",
      "Epoch 9/20\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 0.0551 - acc: 0.9916\n",
      "Epoch 10/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.0577 - acc: 0.9832A: 0s - loss: 0.0470 - acc: 0.98\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0576 - acc: 0.9874\n",
      "Epoch 12/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0628 - acc: 0.9874\n",
      "Epoch 13/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.0407 - acc: 0.9916\n",
      "Epoch 14/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.0642 - acc: 0.9895\n",
      "Epoch 15/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0572 - acc: 0.9874\n",
      "Epoch 16/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.0553 - acc: 0.9874\n",
      "Epoch 17/20\n",
      "476/476 [==============================] - 2s 4ms/step - loss: 0.0593 - acc: 0.9895\n",
      "Epoch 18/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.0480 - acc: 0.9895\n",
      "Epoch 19/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0625 - acc: 0.9916\n",
      "Epoch 20/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0714 - acc: 0.9853\n",
      "Epoch 1/20\n",
      "476/476 [==============================] - 8s 18ms/step - loss: 1.6948 - acc: 0.3887\n",
      "Epoch 2/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.6999 - acc: 0.8046\n",
      "Epoch 3/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.3777 - acc: 0.9097\n",
      "Epoch 4/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.1904 - acc: 0.9664\n",
      "Epoch 5/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.1141 - acc: 0.9895\n",
      "Epoch 6/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.0927 - acc: 0.9811\n",
      "Epoch 7/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.0769 - acc: 0.9874\n",
      "Epoch 8/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0596 - acc: 0.9895\n",
      "Epoch 9/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0639 - acc: 0.9895\n",
      "Epoch 10/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0510 - acc: 0.9853\n",
      "Epoch 11/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0645 - acc: 0.9853\n",
      "Epoch 12/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0479 - acc: 0.9874\n",
      "Epoch 13/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0404 - acc: 0.9895\n",
      "Epoch 14/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0403 - acc: 0.9916\n",
      "Epoch 15/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0813 - acc: 0.9874\n",
      "Epoch 16/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.0703 - acc: 0.9895\n",
      "Epoch 17/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.0707 - acc: 0.9874\n",
      "Epoch 18/20\n",
      "476/476 [==============================] - 1s 3ms/step - loss: 0.0430 - acc: 0.9895\n",
      "Epoch 19/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.0579 - acc: 0.9895\n",
      "Epoch 20/20\n",
      "476/476 [==============================] - 2s 3ms/step - loss: 0.0601 - acc: 0.9874\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.58      0.59        74\n",
      "          1       0.64      0.75      0.69        84\n",
      "          2       0.69      0.70      0.70        77\n",
      "          3       0.78      0.69      0.73        61\n",
      "          4       0.71      0.68      0.69        37\n",
      "          5       0.70      0.62      0.66        42\n",
      "          6       0.76      0.87      0.81        45\n",
      "          7       0.76      0.65      0.70        34\n",
      "          8       0.39      0.39      0.39        74\n",
      "\n",
      "avg / total       0.65      0.65      0.65       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use cross validation predict to make prediction on the entire dataset\n",
    "CNN_pred = cross_val_predict(CNN, X1, ds.Label, cv=10)\n",
    "\n",
    "#Use classification report to get the precision & recall table, compare with prediction and actual labels\n",
    "print(classification_report(ds.Label,CNN_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.96212121212122"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ds.Label, cnn_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scoring = {'acc': 'accuracy',\n",
    "#            'precision': 'precision_macro',\n",
    "#            'recall': 'recall_macro',\n",
    "#            'f1_score' : 'f1_macro'}\n",
    "# cnn_scores = cross_validate(CNN, X1, ds.Label, scoring=scoring,\n",
    "#                          cv=10, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cnn_scores.keys())\n",
    "# print(cnn_scores['test_acc'].mean())\n",
    "# print(cnn_scores['test_precision'].mean())\n",
    "# print(cnn_scores['test_recall'].mean())\n",
    "# print(cnn_scores['test_f1_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 705 samples, validate on 177 samples\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 2.1314 - acc: 0.2709 - val_loss: 1.8444 - val_acc: 0.3390\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.33898, saving model to first.hdf5\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 1s 878us/step - loss: 1.7256 - acc: 0.3844 - val_loss: 1.6324 - val_acc: 0.4237\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.33898 to 0.42373, saving model to first.hdf5\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 1s 913us/step - loss: 1.3070 - acc: 0.5532 - val_loss: 1.5219 - val_acc: 0.4802\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.42373 to 0.48023, saving model to first.hdf5\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 1s 894us/step - loss: 0.8908 - acc: 0.6950 - val_loss: 1.4335 - val_acc: 0.4746\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.48023\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 1s 951us/step - loss: 0.5521 - acc: 0.8227 - val_loss: 1.3064 - val_acc: 0.5876\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.48023 to 0.58757, saving model to first.hdf5\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 1s 942us/step - loss: 0.3828 - acc: 0.8823 - val_loss: 1.4235 - val_acc: 0.5876\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.58757\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 1s 946us/step - loss: 0.2346 - acc: 0.9319 - val_loss: 2.1932 - val_acc: 0.5537\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.58757\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 1s 1ms/step - loss: 0.1036 - acc: 0.9674 - val_loss: 1.9469 - val_acc: 0.5650\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.58757\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 1s 941us/step - loss: 0.1431 - acc: 0.9560 - val_loss: 1.7145 - val_acc: 0.5706\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.58757\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 1s 992us/step - loss: 0.0874 - acc: 0.9773 - val_loss: 1.8499 - val_acc: 0.5480\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.58757\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 1s 966us/step - loss: 0.1211 - acc: 0.9645 - val_loss: 1.9317 - val_acc: 0.5537\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.58757\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 1s 1ms/step - loss: 0.2123 - acc: 0.9291 - val_loss: 1.6884 - val_acc: 0.5480\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.58757\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 1s 1ms/step - loss: 0.0972 - acc: 0.9759 - val_loss: 1.6734 - val_acc: 0.5876\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.58757\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 1s 1ms/step - loss: 0.0411 - acc: 0.9901 - val_loss: 2.2400 - val_acc: 0.5876\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.58757\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 1s 1ms/step - loss: 0.0531 - acc: 0.9872 - val_loss: 2.3367 - val_acc: 0.5706\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.58757\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 1s 1ms/step - loss: 0.0481 - acc: 0.9844 - val_loss: 1.8618 - val_acc: 0.5876\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.58757\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 1s 1ms/step - loss: 0.0358 - acc: 0.9901 - val_loss: 2.2927 - val_acc: 0.5819\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.58757\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 1s 1ms/step - loss: 0.0564 - acc: 0.9830 - val_loss: 1.6803 - val_acc: 0.6328\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.58757 to 0.63277, saving model to first.hdf5\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 1s 1ms/step - loss: 0.1963 - acc: 0.9418 - val_loss: 2.0946 - val_acc: 0.5593\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.63277\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 1s 1ms/step - loss: 0.0652 - acc: 0.9759 - val_loss: 2.4876 - val_acc: 0.5650\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.63277\n"
     ]
    }
   ],
   "source": [
    "CNN_model= fit_model(X=X,y=y,weightsfile = \"first.hdf5\",num_labels=9,seq_len=100,emb_size=100,epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN_model.load_weights('first.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dl = build_model(seq_len=100, emb_size=100, num_labels=9)\n",
    "# CNN = model_dl.fit(X, y, epochs=20, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = cross_val_predict(CNN_model.load_weights('first.hdf5'), X, y, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
